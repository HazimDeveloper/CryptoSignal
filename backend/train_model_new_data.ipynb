{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CryptoSignal Model Training Experiment\n",
    "# Testing different train-test split ratios to optimize model performance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set up visual styling for our plots\n",
    "plt.style.use('dark_background')\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "def fetch_coingecko_data(days=90):\n",
    "    \"\"\"Fetch price data from CoinGecko API\"\"\"\n",
    "    try:\n",
    "        url = \"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart\"\n",
    "        params = {\n",
    "            \"vs_currency\": \"usd\",\n",
    "            \"days\": str(days),\n",
    "            \"interval\": \"daily\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Fetching {days} days of Bitcoin data from CoinGecko\")\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Process price data\n",
    "            prices = []\n",
    "            for price_data in data.get('prices', []):\n",
    "                timestamp = datetime.fromtimestamp(price_data[0]/1000)\n",
    "                price = price_data[1]\n",
    "                prices.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'price': price\n",
    "                })\n",
    "            \n",
    "            # Process volume data\n",
    "            volumes = []\n",
    "            for volume_data in data.get('total_volumes', []):\n",
    "                timestamp = datetime.fromtimestamp(volume_data[0]/1000)\n",
    "                volume = volume_data[1]\n",
    "                volumes.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'volume': volume\n",
    "                })\n",
    "            \n",
    "            # Create DataFrame\n",
    "            price_df = pd.DataFrame(prices)\n",
    "            volume_df = pd.DataFrame(volumes)\n",
    "            \n",
    "            # Merge price and volume data\n",
    "            df = pd.merge(price_df, volume_df, on='timestamp', how='outer')\n",
    "            \n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Failed to fetch CoinGecko data: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fetch_coingecko_data: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# Function to fetch data similar to app.py but simplified for notebook\n",
    "def fetch_coinbase_market_data(days=90):\n",
    "    \"\"\"Fetch market data from Coinbase API\"\"\"\n",
    "    try:\n",
    "        # Calculate time intervals\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=days)\n",
    "        \n",
    "        # Convert to ISO format\n",
    "        start = start_date.isoformat()\n",
    "        end = end_date.isoformat()\n",
    "        \n",
    "        # Coinbase API for BTC-USD historical data\n",
    "        url = \"https://api.exchange.coinbase.com/products/BTC-USD/candles\"\n",
    "        params = {\n",
    "            \"granularity\": 86400,  # Daily candles (86400 seconds)\n",
    "            \"start\": start,\n",
    "            \"end\": end\n",
    "        }\n",
    "        \n",
    "        # Add headers to avoid rate limiting\n",
    "        headers = {\n",
    "            \"User-Agent\": \"TradingDashboardApp/1.0\"\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, headers=headers, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            candles = response.json()\n",
    "            \n",
    "            data = []\n",
    "            for candle in candles:\n",
    "                # Coinbase format: [timestamp, low, high, open, close, volume]\n",
    "                timestamp = datetime.fromtimestamp(candle[0])\n",
    "                low_price = float(candle[1])\n",
    "                high_price = float(candle[2])\n",
    "                open_price = float(candle[3])\n",
    "                close_price = float(candle[4])\n",
    "                volume = float(candle[5])\n",
    "                \n",
    "                data.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'price': close_price,\n",
    "                    'open': open_price,\n",
    "                    'high': high_price,\n",
    "                    'low': low_price,\n",
    "                    'volume': volume\n",
    "                })\n",
    "            \n",
    "            # Sort by timestamp (Coinbase returns in reverse order)\n",
    "            df = pd.DataFrame(data).sort_values('timestamp')\n",
    "            return df\n",
    "            \n",
    "        else:\n",
    "            print(f\"Failed to fetch Coinbase data: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Coinbase market data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Fetch and display raw data\n",
    "print(\"Fetching Bitcoin price data...\")\n",
    "raw_data = fetch_coinbase_market_data(days=90)\n",
    "\n",
    "if raw_data is None:\n",
    "    print(\"Failed to fetch data from Coinbase. Trying alternate source...\")\n",
    "    \n",
    "    # Your coingecko function would go here\n",
    "    raw_data = fetch_coingecko_data(days=90)\n",
    "    \n",
    "    if raw_data is None:\n",
    "        print(\"Failed to fetch data from all sources. Cannot proceed.\")\n",
    "        exit()\n",
    "\n",
    "# 1. Display Raw Data Table\n",
    "print(\"\\n===== Raw Bitcoin Price Data =====\")\n",
    "print(f\"Data shape: {raw_data.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(raw_data.head())\n",
    "\n",
    "print(\"\\nLast 5 rows:\")\n",
    "display(raw_data.tail())\n",
    "\n",
    "# 2. Data Summary Statistics\n",
    "print(\"\\n===== Data Summary Statistics =====\")\n",
    "display(raw_data.describe())\n",
    "\n",
    "# 3. Check for Missing Values\n",
    "print(\"\\n===== Missing Values Check =====\")\n",
    "missing_values = raw_data.isnull().sum()\n",
    "print(f\"Total missing values: {missing_values.sum()}\")\n",
    "display(missing_values)\n",
    "\n",
    "# 4. Visualize Raw Price Data\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(raw_data['timestamp'], raw_data['price'], label='Close Price', color='#4CAF50', linewidth=2)\n",
    "plt.title('Bitcoin Price Over Time (Raw Data)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 5. Visualize Trading Volume\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(raw_data['timestamp'], raw_data['volume'], color='#2196F3', alpha=0.7)\n",
    "plt.title('Bitcoin Trading Volume Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volume')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Visualize Price Range (Candlestick-like)\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.fill_between(raw_data['timestamp'], raw_data['low'], raw_data['high'], \n",
    "                 alpha=0.3, color='#7B1FA2', label='Price Range (High-Low)')\n",
    "plt.plot(raw_data['timestamp'], raw_data['price'], color='white', linewidth=1, label='Close Price')\n",
    "plt.title('Bitcoin Price Range (High-Low)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 7. Daily Returns Calculation and Visualization\n",
    "raw_data['daily_returns'] = raw_data['price'].pct_change() * 100\n",
    "raw_data['daily_returns'] = raw_data['daily_returns'].fillna(0)\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(raw_data['timestamp'], raw_data['daily_returns'], \n",
    "        color=np.where(raw_data['daily_returns'] >= 0, '#4CAF50', '#F44336'))\n",
    "plt.title('Bitcoin Daily Returns (%)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Daily Return (%)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='white', linestyle='-', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 8. Distribution of Daily Returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.histplot(raw_data['daily_returns'], bins=30, kde=True, color='#FFC107')\n",
    "plt.title('Distribution of Daily Returns')\n",
    "plt.xlabel('Daily Return (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axvline(x=0, color='white', linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# 9. Correlation Analysis of Raw Features\n",
    "raw_numeric_data = raw_data.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = raw_numeric_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Raw Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Now proceed with Data Preprocessing\n",
    "print(\"\\n===== Data Preprocessing =====\")\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"Process the data for use with the model\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Make sure 'timestamp' is a column, not an index\n",
    "        if 'timestamp' not in df.columns and df.index.name == 'timestamp':\n",
    "            df = df.reset_index()\n",
    "        \n",
    "        # Make sure we have a 'price' column\n",
    "        price_cols = [col for col in df.columns if col.endswith('price') or col == 'price']\n",
    "        if not price_cols and 'close' in df.columns:\n",
    "            df = df.rename(columns={'close': 'price'})\n",
    "        \n",
    "        # Calculate additional features\n",
    "        # 1. Returns\n",
    "        print(\"Calculating returns...\")\n",
    "        df['returns'] = df['price'].pct_change().fillna(0)\n",
    "        \n",
    "        # 2. Volatility (7-day rolling standard deviation of returns)\n",
    "        print(\"Calculating volatility...\")\n",
    "        df['volatility'] = df['returns'].rolling(window=7).std().fillna(0)\n",
    "        \n",
    "        # 3. Moving averages\n",
    "        print(\"Calculating moving averages...\")\n",
    "        df['price_ma7'] = df['price'].rolling(window=7).mean().fillna(df['price'])\n",
    "        df['price_ma30'] = df['price'].rolling(window=30).mean().fillna(df['price'])\n",
    "        \n",
    "        # 4. Momentum\n",
    "        print(\"Calculating momentum...\")\n",
    "        df['momentum'] = (df['price'] / df['price_ma7'] - 1) * 100\n",
    "        \n",
    "        # 5. RSI calculation\n",
    "        print(\"Calculating RSI...\")\n",
    "        delta = df['price'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "        loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "        \n",
    "        avg_gain = gain.rolling(window=14).mean()\n",
    "        avg_loss = loss.rolling(window=14).mean()\n",
    "        \n",
    "        rs = avg_gain / avg_loss.replace(0, np.nan).fillna(1)\n",
    "        df['rsi'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # 6. Add market regime based on trend\n",
    "        print(\"Determining market regimes...\")\n",
    "        if 'returns' in df.columns:\n",
    "            # Simple regime based on returns trend\n",
    "            df['market_regime'] = 0  # Neutral by default\n",
    "            \n",
    "            # Trending up: regime 1\n",
    "            df.loc[df['returns'].rolling(10).mean() > 0.001, 'market_regime'] = 1\n",
    "            \n",
    "            # Trending down: regime 2\n",
    "            df.loc[df['returns'].rolling(10).mean() < -0.001, 'market_regime'] = 2\n",
    "        \n",
    "        # 7. Add volume features if available\n",
    "        if 'volume' in df.columns:\n",
    "            print(\"Calculating volume features...\")\n",
    "            df['volume_change'] = df['volume'].pct_change().fillna(0)\n",
    "            df['volume_ma7'] = df['volume'].rolling(window=7).mean().fillna(df['volume'])\n",
    "            df['volume_momentum'] = (df['volume'] / df['volume_ma7'] - 1) * 100\n",
    "        \n",
    "        print(f\"Processed data shape: {df.shape}\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Process the data\n",
    "processed_df = process_data(raw_data)\n",
    "\n",
    "# Display processed data\n",
    "print(\"\\n===== Processed Data =====\")\n",
    "print(f\"Data shape after preprocessing: {processed_df.shape}\")\n",
    "print(\"\\nNew features created:\")\n",
    "new_features = [col for col in processed_df.columns if col not in raw_data.columns]\n",
    "print(\", \".join(new_features))\n",
    "\n",
    "print(\"\\nFirst 5 rows of processed data:\")\n",
    "display(processed_df.head())\n",
    "\n",
    "# 10. Visualize processed features\n",
    "print(\"\\n===== Visualizing Processed Features =====\")\n",
    "\n",
    "# Plot price with moving averages\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(processed_df['timestamp'], processed_df['price'], label='Price', color='white', alpha=0.8)\n",
    "plt.plot(processed_df['timestamp'], processed_df['price_ma7'], label='7-Day MA', color='#4CAF50', linewidth=2)\n",
    "plt.plot(processed_df['timestamp'], processed_df['price_ma30'], label='30-Day MA', color='#2196F3', linewidth=2)\n",
    "plt.title('Bitcoin Price with Moving Averages')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot RSI\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(processed_df['timestamp'], processed_df['rsi'], color='#FFC107', linewidth=2)\n",
    "plt.axhline(y=70, color='#F44336', linestyle='--', alpha=0.5, label='Overbought (70)')\n",
    "plt.axhline(y=30, color='#4CAF50', linestyle='--', alpha=0.5, label='Oversold (30)')\n",
    "plt.title('Relative Strength Index (RSI)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('RSI')\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot market regimes\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(processed_df['timestamp'], processed_df['price'], label='Price', color='white', alpha=0.6)\n",
    "\n",
    "# Color regions based on market regime\n",
    "for i in range(len(processed_df)-1):\n",
    "    if processed_df['market_regime'].iloc[i] == 1:  # Bullish\n",
    "        plt.axvspan(processed_df['timestamp'].iloc[i], processed_df['timestamp'].iloc[i+1], \n",
    "                   alpha=0.3, color='green')\n",
    "    elif processed_df['market_regime'].iloc[i] == 2:  # Bearish\n",
    "        plt.axvspan(processed_df['timestamp'].iloc[i], processed_df['timestamp'].iloc[i+1], \n",
    "                   alpha=0.3, color='red')\n",
    "\n",
    "plt.title('Market Regimes')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 11. Correlation Analysis of Processed Features\n",
    "processed_numeric_data = processed_df.select_dtypes(include=[np.number])\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix = processed_numeric_data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Processed Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 12. Feature Distribution\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, feature in enumerate(new_features[:min(9, len(new_features))]):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.histplot(processed_df[feature], kde=True)\n",
    "    plt.title(feature)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 13. Time Series Decomposition (Trend, Seasonality, Residual)\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(processed_df['timestamp'], processed_df['price'], label='Original Price', color='white')\n",
    "plt.title('Original Bitcoin Price')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(processed_df['timestamp'], processed_df['price_ma30'], label='Trend (30-day MA)', color='#4CAF50')\n",
    "plt.title('Price Trend (30-day Moving Average)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "residual = processed_df['price'] - processed_df['price_ma30']\n",
    "plt.plot(processed_df['timestamp'], residual, label='Residual', color='#F44336')\n",
    "plt.title('Price Residual (Price - Trend)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 14. Summary of data preparation\n",
    "print(\"\\n===== Data Preparation Summary =====\")\n",
    "print(f\"Total data points: {len(processed_df)}\")\n",
    "print(f\"Time range: {processed_df['timestamp'].min()} to {processed_df['timestamp'].max()}\")\n",
    "print(f\"Price range: ${processed_df['price'].min():.2f} to ${processed_df['price'].max():.2f}\")\n",
    "print(f\"Average price: ${processed_df['price'].mean():.2f}\")\n",
    "print(f\"Average daily return: {processed_df['returns'].mean()*100:.2f}%\")\n",
    "print(f\"Market regime distribution:\")\n",
    "regime_counts = processed_df['market_regime'].value_counts()\n",
    "for regime, count in regime_counts.items():\n",
    "    regime_name = {0: 'Neutral', 1: 'Bullish', 2: 'Bearish'}.get(regime, 'Unknown')\n",
    "    percentage = count / len(processed_df) * 100\n",
    "    print(f\"  - {regime_name}: {count} data points ({percentage:.1f}%)\")\n",
    "\n",
    "print(\"\\nData is now ready for the train-test split experiment!\")\n",
    "\n",
    "# Function to fetch data from CoinGecko API as fallback\n",
    "def fetch_coingecko_data(days=90):\n",
    "    \"\"\"Fetch price data from CoinGecko API\"\"\"\n",
    "    try:\n",
    "        # CoinGecko API for Bitcoin price history\n",
    "        url = \"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart\"\n",
    "        params = {\n",
    "            \"vs_currency\": \"usd\",\n",
    "            \"days\": str(days),\n",
    "            \"interval\": \"daily\"\n",
    "        }\n",
    "        \n",
    "        print(f\"Fetching {days} days of Bitcoin data from CoinGecko\")\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Process price data\n",
    "            prices = []\n",
    "            for price_data in data.get('prices', []):\n",
    "                timestamp = datetime.fromtimestamp(price_data[0]/1000)\n",
    "                price = price_data[1]\n",
    "                prices.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'price': price\n",
    "                })\n",
    "            \n",
    "            # Process volume data\n",
    "            volumes = []\n",
    "            for volume_data in data.get('total_volumes', []):\n",
    "                timestamp = datetime.fromtimestamp(volume_data[0]/1000)\n",
    "                volume = volume_data[1]\n",
    "                volumes.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'volume': volume\n",
    "                })\n",
    "            \n",
    "            # Create DataFrame\n",
    "            price_df = pd.DataFrame(prices)\n",
    "            volume_df = pd.DataFrame(volumes)\n",
    "            \n",
    "            # Merge price and volume data\n",
    "            df = pd.merge(price_df, volume_df, on='timestamp', how='outer')\n",
    "            \n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Failed to fetch CoinGecko data: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in fetch_coingecko_data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to process data for model training similar to process_data() in app.py\n",
    "def process_data(df):\n",
    "    \"\"\"Process the data for use with the model\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Make sure 'timestamp' is a column, not an index\n",
    "        if 'timestamp' not in df.columns and df.index.name == 'timestamp':\n",
    "            df = df.reset_index()\n",
    "        \n",
    "        # Make sure we have a 'price' column\n",
    "        price_cols = [col for col in df.columns if col.endswith('price') or col == 'price']\n",
    "        if not price_cols and 'close' in df.columns:\n",
    "            df = df.rename(columns={'close': 'price'})\n",
    "        \n",
    "        # Calculate additional features\n",
    "        if 'price' in df.columns:\n",
    "            # Returns\n",
    "            df['returns'] = df['price'].pct_change().fillna(0)\n",
    "            \n",
    "            # Volatility (7-day rolling standard deviation of returns)\n",
    "            df['volatility'] = df['returns'].rolling(window=7).std().fillna(0)\n",
    "            \n",
    "            # Moving averages\n",
    "            df['price_ma7'] = df['price'].rolling(window=7).mean().fillna(df['price'])\n",
    "            df['price_ma30'] = df['price'].rolling(window=30).mean().fillna(df['price'])\n",
    "            \n",
    "            # Momentum\n",
    "            df['momentum'] = (df['price'] / df['price_ma7'] - 1) * 100\n",
    "            \n",
    "            # RSI calculation\n",
    "            delta = df['price'].diff()\n",
    "            gain = (delta.where(delta > 0, 0)).fillna(0)\n",
    "            loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
    "            \n",
    "            avg_gain = gain.rolling(window=14).mean()\n",
    "            avg_loss = loss.rolling(window=14).mean()\n",
    "            \n",
    "            rs = avg_gain / avg_loss.replace(0, np.nan).fillna(1)\n",
    "            df['rsi'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Add market regime based on trend\n",
    "        if 'returns' in df.columns:\n",
    "            # Simple regime based on returns trend\n",
    "            df['market_regime'] = 0  # Neutral by default\n",
    "            \n",
    "            # Trending up: regime 1\n",
    "            df.loc[df['returns'].rolling(10).mean() > 0.001, 'market_regime'] = 1\n",
    "            \n",
    "            # Trending down: regime 2\n",
    "            df.loc[df['returns'].rolling(10).mean() < -0.001, 'market_regime'] = 2\n",
    "        \n",
    "        # Add volume features if available\n",
    "        if 'volume' in df.columns:\n",
    "            df['volume_change'] = df['volume'].pct_change().fillna(0)\n",
    "            df['volume_ma7'] = df['volume'].rolling(window=7).mean().fillna(df['volume'])\n",
    "            df['volume_momentum'] = (df['volume'] / df['volume_ma7'] - 1) * 100\n",
    "        \n",
    "        print(f\"Processed data shape: {df.shape}\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Experiment with different train-test split ratios\n",
    "def build_model_with_ratio(df, window_size=7, target_col='returns', split_ratio=0.8):\n",
    "    \"\"\"Build a CNN-LSTM model with specific train-test split ratio\"\"\"\n",
    "    if df is None or len(df) < window_size + 10:\n",
    "        print(f\"Insufficient data for model. Need at least {window_size + 10} rows\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    try:\n",
    "        # Make sure we have the target column\n",
    "        if target_col not in df.columns:\n",
    "            if 'returns' in df.columns:\n",
    "                target_col = 'returns'\n",
    "            else:\n",
    "                print(f\"Target column '{target_col}' not found in data\")\n",
    "                return None, None, None, None, None\n",
    "        \n",
    "        print(f\"Building model with target column: {target_col} and split ratio: {split_ratio}\")\n",
    "        \n",
    "        # Drop non-numeric columns and timestamp\n",
    "        numeric_df = df.select_dtypes(include=['number'])\n",
    "        \n",
    "        # Remove columns with all NaN or all same values\n",
    "        cols_to_keep = [col for col in numeric_df.columns \n",
    "                       if not numeric_df[col].isna().all() \n",
    "                       and numeric_df[col].nunique() > 1]\n",
    "        \n",
    "        # Keep only relevant columns\n",
    "        numeric_df = numeric_df[cols_to_keep]\n",
    "        \n",
    "        # Create target variable (next period's return)\n",
    "        y = numeric_df[target_col].shift(-1).dropna()\n",
    "        \n",
    "        # Keep only rows that have a target value\n",
    "        X = numeric_df.iloc[:len(y)]\n",
    "        \n",
    "        # Scale the features\n",
    "        scaler = MinMaxScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Prepare input sequences\n",
    "        X_sequences = []\n",
    "        y_values = []\n",
    "        \n",
    "        for i in range(len(X_scaled) - window_size):\n",
    "            X_sequences.append(X_scaled[i:i+window_size])\n",
    "            y_values.append(y.iloc[i+window_size])\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X_sequences = np.array(X_sequences)\n",
    "        y_values = np.array(y_values)\n",
    "        \n",
    "        # Split into training and testing sets\n",
    "        split_idx = int(len(X_sequences) * split_ratio)\n",
    "        X_train, X_test = X_sequences[:split_idx], X_sequences[split_idx:]\n",
    "        y_train, y_test = y_values[:split_idx], y_values[split_idx:]\n",
    "        \n",
    "        # Build CNN-LSTM model\n",
    "        model = tf.keras.Sequential([\n",
    "            # CNN layers for feature extraction\n",
    "            Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(window_size, X.shape[1])),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "            \n",
    "            # LSTM layers for sequence learning\n",
    "            LSTM(50, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(50),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            # Dense output layers\n",
    "            Dense(25, activation='relu'),\n",
    "            Dense(1)  # Prediction output\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Train the model with early stopping\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Training the CNN-LSTM model with {len(X_train)} training samples and {len(X_test)} test samples...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,  # Maximum epochs\n",
    "            batch_size=32,\n",
    "            validation_data=(X_test, y_test),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Model evaluation with {split_ratio:.1f} split ratio:\")\n",
    "        print(f\"MSE: {mse:.6f}\")\n",
    "        print(f\"MAE: {mae:.6f}\")\n",
    "        print(f\"R²: {r2:.6f}\")\n",
    "        \n",
    "        return model, scaler, X.columns, history, {\n",
    "            'X_train': X_train, 'y_train': y_train,\n",
    "            'X_test': X_test, 'y_test': y_test,\n",
    "            'y_pred': y_pred, 'mse': mse, 'mae': mae, 'r2': r2\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error building model: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None\n",
    "\n",
    "# Function to generate trading signals based on the model\n",
    "def generate_signals(model, scaler, df, features, window_size=7, threshold=0.001):\n",
    "    \"\"\"Generate trading signals based on model predictions\"\"\"\n",
    "    if model is None or scaler is None or df is None:\n",
    "        print(\"Missing required inputs for signal generation\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Make a copy of the dataframe\n",
    "        signal_df = df.copy()\n",
    "        \n",
    "        # Select features used in training\n",
    "        X = signal_df[features].copy()\n",
    "        \n",
    "        # Scale the features\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        # Generate predictions for each possible window\n",
    "        predictions = []\n",
    "        timestamps = []\n",
    "        \n",
    "        for i in range(len(X_scaled) - window_size + 1):\n",
    "            window_data = X_scaled[i:i+window_size].reshape(1, window_size, len(features))\n",
    "            pred = model.predict(window_data, verbose=0)[0][0]\n",
    "            predictions.append(pred)\n",
    "            timestamps.append(signal_df['timestamp'].iloc[i+window_size-1])\n",
    "        \n",
    "        # Create a prediction dataframe\n",
    "        pred_df = pd.DataFrame({\n",
    "            'timestamp': timestamps,\n",
    "            'predicted_return': predictions\n",
    "        })\n",
    "        \n",
    "        # Generate signals based on predicted returns\n",
    "        pred_df['signal'] = 'HOLD'\n",
    "        pred_df.loc[pred_df['predicted_return'] > threshold, 'signal'] = 'BUY'\n",
    "        pred_df.loc[pred_df['predicted_return'] < -threshold, 'signal'] = 'SELL'\n",
    "        \n",
    "        # Calculate signal confidence\n",
    "        pred_df['confidence'] = abs(pred_df['predicted_return']) * 100\n",
    "        \n",
    "        # Merge signals back with original data\n",
    "        result_df = pd.merge(signal_df, pred_df, on='timestamp', how='left')\n",
    "        \n",
    "        # Forward fill signals for any missing values\n",
    "        result_df['signal'] = result_df['signal'].fillna('HOLD')\n",
    "        result_df['confidence'] = result_df['confidence'].fillna(0)\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating signals: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to evaluate trading strategy performance\n",
    "def evaluate_performance(signals_df, price_col='price'):\n",
    "    \"\"\"Evaluate trading strategy performance metrics with various criteria\"\"\"\n",
    "    if signals_df is None:\n",
    "        print(\"No signals dataframe provided for evaluation\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Verify signal column exists\n",
    "        if 'signal' not in signals_df.columns:\n",
    "            print(\"Signal column not found in dataframe\")\n",
    "            return None\n",
    "        \n",
    "        # Find price column if not specified\n",
    "        if price_col not in signals_df.columns:\n",
    "            price_cols = [col for col in signals_df.columns if col.endswith('price') or col == 'price']\n",
    "            if not price_cols:\n",
    "                print(\"No price column found for performance evaluation\")\n",
    "                return None\n",
    "            price_col = price_cols[0]\n",
    "        \n",
    "        # Find or create returns column\n",
    "        returns_col = 'returns'\n",
    "        if returns_col not in signals_df.columns:\n",
    "            signals_df[returns_col] = signals_df[price_col].pct_change().fillna(0)\n",
    "        \n",
    "        # Calculate strategy positions\n",
    "        signals_df['position'] = 0\n",
    "        signals_df.loc[signals_df['signal'] == 'BUY', 'position'] = 1\n",
    "        signals_df.loc[signals_df['signal'] == 'SELL', 'position'] = -1\n",
    "        \n",
    "        # Shift positions (implement on next period)\n",
    "        signals_df['position'] = signals_df['position'].shift(1).fillna(0)\n",
    "        \n",
    "        # Calculate strategy returns\n",
    "        signals_df['strategy_return'] = signals_df['position'] * signals_df[returns_col]\n",
    "        \n",
    "        # Calculate cumulative returns\n",
    "        signals_df['cumulative_return'] = (1 + signals_df['strategy_return']).cumprod()\n",
    "        \n",
    "        # Calculate buy and hold returns\n",
    "        signals_df['buy_hold_return'] = (1 + signals_df[returns_col]).cumprod()\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        # Sharpe Ratio (assuming daily data)\n",
    "        annualization_factor = np.sqrt(252)\n",
    "        \n",
    "        mean_return = signals_df['strategy_return'].mean()\n",
    "        std_return = max(signals_df['strategy_return'].std(), 0.0001)  # Avoid division by zero\n",
    "        sharpe_ratio = mean_return / std_return * annualization_factor\n",
    "        \n",
    "        # Maximum Drawdown\n",
    "        cum_returns = signals_df['cumulative_return']\n",
    "        if len(cum_returns) > 0:\n",
    "            rolling_max = cum_returns.cummax()\n",
    "            drawdown = (cum_returns / rolling_max - 1)\n",
    "            max_drawdown = abs(drawdown.min())\n",
    "        else:\n",
    "            max_drawdown = 0\n",
    "        \n",
    "        # Trade Frequency\n",
    "        position_changes = signals_df['position'].diff() != 0\n",
    "        trade_frequency = position_changes.sum() / len(signals_df)\n",
    "        \n",
    "        # Signal counts\n",
    "        buy_signals = (signals_df['signal'] == 'BUY').sum()\n",
    "        sell_signals = (signals_df['signal'] == 'SELL').sum()\n",
    "        hold_signals = (signals_df['signal'] == 'HOLD').sum()\n",
    "        \n",
    "        # Final performance\n",
    "        final_return = signals_df['cumulative_return'].iloc[-1] - 1\n",
    "        buy_hold_return = signals_df['buy_hold_return'].iloc[-1] - 1\n",
    "        \n",
    "        # Store performance metrics\n",
    "        performance = {\n",
    "            'sharpe_ratio': float(sharpe_ratio),\n",
    "            'max_drawdown': float(max_drawdown),\n",
    "            'trade_frequency': float(trade_frequency),\n",
    "            'buy_signals': int(buy_signals),\n",
    "            'sell_signals': int(sell_signals),\n",
    "            'hold_signals': int(hold_signals),\n",
    "            'final_return': float(final_return),\n",
    "            'buy_hold_return': float(buy_hold_return),\n",
    "            'outperformance': float(final_return - buy_hold_return),\n",
    "            'meets_sharpe_ratio': bool(sharpe_ratio >= 1.8),\n",
    "            'meets_drawdown': bool(max_drawdown <= 0.4),\n",
    "            'meets_frequency': bool(trade_frequency >= 0.03),\n",
    "            'meets_criteria': bool(sharpe_ratio >= 1.8 and max_drawdown <= 0.4 and trade_frequency >= 0.03)\n",
    "        }\n",
    "        \n",
    "        return performance, signals_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating performance: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "# Function to visualize training history\n",
    "def plot_training_history(history, title='Model Training History'):\n",
    "    \"\"\"Plot training and validation loss\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    return plt\n",
    "\n",
    "# Function to visualize predictions vs actual values\n",
    "def plot_predictions(y_test, y_pred, title='Model Predictions vs Actual Values'):\n",
    "    \"\"\"Plot test predictions against actual values\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test, label='Actual Returns', alpha=0.7)\n",
    "    plt.plot(y_pred, label='Predicted Returns', alpha=0.7)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Returns')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    return plt\n",
    "\n",
    "# Function to visualize trading signals and cumulative returns\n",
    "def plot_trading_strategy(signals_df, title='Trading Strategy Performance'):\n",
    "    \"\"\"Plot price, signals, and cumulative returns\"\"\"\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10), sharex=True, gridspec_kw={'height_ratios': [2, 1]})\n",
    "    \n",
    "    # Plot price on first subplot\n",
    "    ax1.plot(signals_df['timestamp'], signals_df['price'], label='Price', color='white', alpha=0.8)\n",
    "    ax1.set_title('Bitcoin Price with Trading Signals')\n",
    "    ax1.set_ylabel('Price (USD)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot buy signals\n",
    "    buy_signals = signals_df[signals_df['signal'] == 'BUY']\n",
    "    ax1.scatter(buy_signals['timestamp'], buy_signals['price'], \n",
    "               marker='^', color='green', s=100, label='Buy Signal')\n",
    "    \n",
    "    # Plot sell signals\n",
    "    sell_signals = signals_df[signals_df['signal'] == 'SELL']\n",
    "    ax1.scatter(sell_signals['timestamp'], sell_signals['price'], \n",
    "               marker='v', color='red', s=100, label='Sell Signal')\n",
    "    \n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot cumulative returns on second subplot\n",
    "    ax2.plot(signals_df['timestamp'], signals_df['cumulative_return'], \n",
    "            label='Strategy Returns', color='#4CAF50', linewidth=2)\n",
    "    ax2.plot(signals_df['timestamp'], signals_df['buy_hold_return'], \n",
    "            label='Buy & Hold Returns', color='#2196F3', linewidth=2, alpha=0.7)\n",
    "    ax2.set_title('Cumulative Returns')\n",
    "    ax2.set_ylabel('Returns')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, (ax1, ax2)\n",
    "\n",
    "# Function to visualize performance metrics across different split ratios\n",
    "def plot_performance_comparison(performance_metrics, split_ratios):\n",
    "    \"\"\"Plot performance metrics for different train-test split ratios\"\"\"\n",
    "    metrics = ['sharpe_ratio', 'max_drawdown', 'trade_frequency', 'final_return']\n",
    "    titles = ['Sharpe Ratio', 'Maximum Drawdown', 'Trade Frequency', 'Final Return']\n",
    "    colors = ['#4CAF50', '#F44336', '#2196F3', '#FFC107']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (metric, title, color) in enumerate(zip(metrics, titles, colors)):\n",
    "        values = [metrics[metric] for metrics in performance_metrics]\n",
    "        axes[i].bar(split_ratios, values, color=color, alpha=0.7)\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].set_xlabel('Train-Test Split Ratio')\n",
    "        axes[i].set_ylabel(title)\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for j, value in enumerate(values):\n",
    "            axes[i].text(j, value, f'{value:.4f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, axes\n",
    "\n",
    "# Main experiment function to run the train-test ratio comparison\n",
    "def run_train_test_ratio_experiment():\n",
    "    \"\"\"Run experiment with different train-test split ratios\"\"\"\n",
    "    print(\"Starting train-test split ratio experiment...\")\n",
    "    \n",
    "    # Fetch and process data\n",
    "    print(\"Fetching data...\")\n",
    "    df = fetch_coinbase_market_data(days=90)\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"Trying alternative data source...\")\n",
    "        df = fetch_coingecko_data(days=90)\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"Failed to fetch data from any source. Cannot proceed with experiment.\")\n",
    "        return None\n",
    "    \n",
    "    # Process data\n",
    "    print(\"Processing data...\")\n",
    "    processed_df = process_data(df)\n",
    "    \n",
    "    if processed_df is None:\n",
    "        print(\"Failed to process data. Cannot proceed with experiment.\")\n",
    "        return None\n",
    "    \n",
    "    # Define split ratios to test\n",
    "    split_ratios = [0.7, 0.8, 0.9]\n",
    "    \n",
    "    # Store results\n",
    "    results = []\n",
    "    performance_metrics = []\n",
    "    \n",
    "    # Run experiment for each split ratio\n",
    "    for ratio in split_ratios:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing train-test split ratio: {ratio}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Build and train model\n",
    "        model, scaler, features, history, evaluation = build_model_with_ratio(\n",
    "            processed_df, window_size=7, target_col='returns', split_ratio=ratio\n",
    "        )\n",
    "        \n",
    "        if model is None:\n",
    "            print(f\"Failed to build model with ratio {ratio}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Generate signals\n",
    "        signals_df = generate_signals(model, scaler, processed_df, features)\n",
    "        \n",
    "        if signals_df is None:\n",
    "            print(f\"Failed to generate signals with ratio {ratio}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Evaluate performance\n",
    "        performance, signals_with_returns = evaluate_performance(signals_df)\n",
    "        \n",
    "        if performance is None:\n",
    "            print(f\"Failed to evaluate performance with ratio {ratio}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'ratio': ratio,\n",
    "            'model': model,\n",
    "            'scaler': scaler,\n",
    "            'features': features,\n",
    "            'history': history,\n",
    "            'evaluation': evaluation,\n",
    "            'signals_df': signals_with_returns,\n",
    "            'performance': performance\n",
    "        })\n",
    "        \n",
    "        performance_metrics.append(performance)\n",
    "        \n",
    "        # Print performance summary\n",
    "        print(f\"\\nPerformance Summary for {ratio} split ratio:\")\n",
    "        print(f\"Sharpe Ratio: {performance['sharpe_ratio']:.4f}\")\n",
    "        print(f\"Maximum Drawdown: {performance['max_drawdown']:.4f}\")\n",
    "        print(f\"Trade Frequency: {performance['trade_frequency']:.4f}\")\n",
    "        print(f\"Final Return: {performance['final_return']:.4f}\")\n",
    "        print(f\"Buy & Hold Return: {performance['buy_hold_return']:.4f}\")\n",
    "        print(f\"Outperformance: {performance['outperformance']:.4f}\")\n",
    "        print(f\"Signal Counts: Buy={performance['buy_signals']}, Sell={performance['sell_signals']}, Hold={performance['hold_signals']}\")\n",
    "        print(f\"Meets Criteria: {performance['meets_criteria']}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No successful experiments. Cannot compare results.\")\n",
    "        return None\n",
    "    \n",
    "    # Compare results and select best model\n",
    "    best_result = max(results, key=lambda x: x['performance']['sharpe_ratio'])\n",
    "    best_ratio = best_result['ratio']\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Best Split Ratio: {best_ratio}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Sharpe Ratio: {best_result['performance']['sharpe_ratio']:.4f}\")\n",
    "    print(f\"Maximum Drawdown: {best_result['performance']['max_drawdown']:.4f}\")\n",
    "    print(f\"Trade Frequency: {best_result['performance']['trade_frequency']:.4f}\")\n",
    "    print(f\"Final Return: {best_result['performance']['final_return']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'results': results,\n",
    "        'performance_metrics': performance_metrics,\n",
    "        'split_ratios': split_ratios,\n",
    "        'best_result': best_result,\n",
    "        'best_ratio': best_ratio,\n",
    "        'processed_df': processed_df\n",
    "    }\n",
    "\n",
    "# Run the experiment\n",
    "experiment_results = run_train_test_ratio_experiment()\n",
    "\n",
    "def visualize_ratio_comparison(experiment_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations comparing the performance metrics\n",
    "    across different train-test split ratios\n",
    "    \"\"\"\n",
    "    if not experiment_results:\n",
    "        print(\"No experiment results to visualize\")\n",
    "        return\n",
    "    \n",
    "    split_ratios = experiment_results['split_ratios']\n",
    "    performance_metrics = experiment_results['performance_metrics']\n",
    "    best_ratio = experiment_results['best_ratio']\n",
    "    \n",
    "    # Create a DataFrame for easier manipulation\n",
    "    metrics_df = pd.DataFrame(performance_metrics)\n",
    "    metrics_df['split_ratio'] = split_ratios\n",
    "    \n",
    "    # Set split_ratio as index for better display\n",
    "    metrics_df = metrics_df.set_index('split_ratio')\n",
    "    \n",
    "    # 1. Tabular Comparison of All Metrics\n",
    "    print(\"\\n===== Train-Test Split Ratio Comparison (Tabular) =====\")\n",
    "    comparison_cols = [\n",
    "        'sharpe_ratio', 'max_drawdown', 'trade_frequency', \n",
    "        'final_return', 'buy_hold_return', 'outperformance',\n",
    "        'buy_signals', 'sell_signals', 'hold_signals'\n",
    "    ]\n",
    "    \n",
    "    # Highlight the best ratio with a custom formatter\n",
    "    def highlight_best(s):\n",
    "        is_best = pd.Series(data=False, index=s.index)\n",
    "        if s.name == 'sharpe_ratio' or s.name == 'final_return' or s.name == 'outperformance':\n",
    "            is_best = s == s.max()\n",
    "        elif s.name == 'max_drawdown':\n",
    "            is_best = s == s.min()\n",
    "        return ['background-color: #4CAF50; color: white' if v else '' for v in is_best]\n",
    "    \n",
    "    # Display styled DataFrame with conditional formatting\n",
    "    styled_df = metrics_df[comparison_cols].style.apply(highlight_best)\n",
    "    display(styled_df)\n",
    "    \n",
    "    # 2. Bar Chart Comparison for Key Metrics\n",
    "    key_metrics = ['sharpe_ratio', 'max_drawdown', 'trade_frequency', 'final_return']\n",
    "    titles = ['Sharpe Ratio', 'Maximum Drawdown', 'Trade Frequency', 'Final Return']\n",
    "    colors = ['#4CAF50', '#F44336', '#2196F3', '#FFC107']\n",
    "    \n",
    "    plt.figure(figsize=(16, 12))\n",
    "    for i, (metric, title, color) in enumerate(zip(key_metrics, titles, colors)):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        # Get values for each ratio\n",
    "        values = [metrics[metric] for metrics in performance_metrics]\n",
    "        \n",
    "        # Create bar chart\n",
    "        bars = plt.bar(split_ratios, values, color=color, alpha=0.7)\n",
    "        \n",
    "        # Highlight the best ratio\n",
    "        best_idx = values.index(max(values)) if metric != 'max_drawdown' else values.index(min(values))\n",
    "        bars[best_idx].set_color('gold')\n",
    "        bars[best_idx].set_alpha(1.0)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for j, value in enumerate(values):\n",
    "            plt.text(j, value, f'{value:.4f}', ha='center', va='bottom')\n",
    "        \n",
    "        # Add target lines if applicable\n",
    "        if metric == 'sharpe_ratio':\n",
    "            plt.axhline(y=1.8, color='white', linestyle='--', alpha=0.5, label='Target: ≥ 1.8')\n",
    "        elif metric == 'max_drawdown':\n",
    "            plt.axhline(y=0.4, color='white', linestyle='--', alpha=0.5, label='Target: ≤ 0.4')\n",
    "        elif metric == 'trade_frequency':\n",
    "            plt.axhline(y=0.03, color='white', linestyle='--', alpha=0.5, label='Target: ≥ 0.03')\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel('Train-Test Split Ratio')\n",
    "        plt.ylabel(title)\n",
    "        plt.xticks(range(len(split_ratios)), split_ratios)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        if metric in ['sharpe_ratio', 'max_drawdown', 'trade_frequency']:\n",
    "            plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Comparison of Key Metrics Across Different Train-Test Split Ratios', \n",
    "                fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Radar Chart for Multi-dimensional Comparison\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Prepare data for radar chart\n",
    "    categories = ['Sharpe Ratio', 'Final Return', 'Trade Frequency', \n",
    "                 'Signal Accuracy', 'Computational\\nEfficiency']\n",
    "    \n",
    "    # Normalize metrics to 0-1 scale for radar chart\n",
    "    normalized_metrics = []\n",
    "    \n",
    "    for ratio_idx, ratio in enumerate(split_ratios):\n",
    "        # Extract metrics for this ratio\n",
    "        ratio_metrics = performance_metrics[ratio_idx]\n",
    "        \n",
    "        # Normalize each metric (higher is better for all)\n",
    "        sharpe_ratio = ratio_metrics['sharpe_ratio'] / max([m['sharpe_ratio'] for m in performance_metrics])\n",
    "        final_return = ratio_metrics['final_return'] / max([m['final_return'] for m in performance_metrics])\n",
    "        trade_freq = ratio_metrics['trade_frequency'] / max([m['trade_frequency'] for m in performance_metrics])\n",
    "        \n",
    "        # Invert max_drawdown since lower is better\n",
    "        max_dd_values = [m['max_drawdown'] for m in performance_metrics]\n",
    "        signal_accuracy = 1 - (ratio_metrics['max_drawdown'] / max(max_dd_values))\n",
    "        \n",
    "        # Computational efficiency (more training data = lower efficiency)\n",
    "        comp_efficiency = 1 - ((ratio - min(split_ratios)) / (max(split_ratios) - min(split_ratios)))\n",
    "        \n",
    "        normalized_metrics.append([sharpe_ratio, final_return, trade_freq, signal_accuracy, comp_efficiency])\n",
    "    \n",
    "    # Set up radar chart\n",
    "    angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    \n",
    "    # Add lines for each ratio\n",
    "    for idx, ratio in enumerate(split_ratios):\n",
    "        values = normalized_metrics[idx]\n",
    "        values += values[:1]  # Close the loop\n",
    "        \n",
    "        color = 'gold' if ratio == best_ratio else f'C{idx}'\n",
    "        linewidth = 3 if ratio == best_ratio else 2\n",
    "        alpha = 1.0 if ratio == best_ratio else 0.7\n",
    "        \n",
    "        ax.plot(angles, values, 'o-', linewidth=linewidth, \n",
    "                color=color, label=f'{ratio*100:.0f}//{(1-ratio)*100:.0f} Split', alpha=alpha)\n",
    "        ax.fill(angles, values, color=color, alpha=0.1)\n",
    "    \n",
    "    # Set up radar chart properties\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'])\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add legend\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "    \n",
    "    plt.title('Multi-dimensional Comparison of Train-Test Split Ratios', size=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Line Chart Comparison of Cumulative Returns\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    \n",
    "    # Get signals dataframes for each ratio\n",
    "    best_idx = split_ratios.index(best_ratio)\n",
    "    \n",
    "    # Loop through ratios and plot cumulative returns\n",
    "    for idx, ratio in enumerate(split_ratios):\n",
    "        signals_df = experiment_results['results'][idx]['signals_df']\n",
    "        \n",
    "        # Plot strategy returns\n",
    "        linewidth = 3 if ratio == best_ratio else 2\n",
    "        alpha = 1.0 if ratio == best_ratio else 0.7\n",
    "        \n",
    "        plt.plot(signals_df['timestamp'], signals_df['cumulative_return'], \n",
    "                linewidth=linewidth, alpha=alpha,\n",
    "                label=f'{ratio*100:.0f}//{(1-ratio)*100:.0f} Split')\n",
    "    \n",
    "    # Add buy and hold returns from best model for comparison\n",
    "    best_signals_df = experiment_results['results'][best_idx]['signals_df']\n",
    "    plt.plot(best_signals_df['timestamp'], best_signals_df['buy_hold_return'], \n",
    "            linewidth=2, linestyle='--', color='white', alpha=0.7,\n",
    "            label='Buy & Hold')\n",
    "    \n",
    "    plt.title('Cumulative Returns Comparison Across Different Train-Test Split Ratios')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 5. Signal Distribution Comparison\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    \n",
    "    for idx, ratio in enumerate(split_ratios):\n",
    "        signals_df = experiment_results['results'][idx]['signals_df']\n",
    "        signal_counts = signals_df['signal'].value_counts()\n",
    "        \n",
    "        # Create pie chart\n",
    "        plt.subplot(1, len(split_ratios), idx+1)\n",
    "        \n",
    "        colors = ['#4CAF50', '#F44336', '#FFC107']  # Green, Red, Yellow\n",
    "        explode = [0.1 if signal in ['BUY', 'SELL'] else 0 for signal in signal_counts.index]\n",
    "        \n",
    "        plt.pie(signal_counts, labels=signal_counts.index, autopct='%1.1f%%', \n",
    "                colors=colors[:len(signal_counts)], startangle=90, explode=explode)\n",
    "        plt.title(f'Signal Distribution\\n{ratio*100:.0f}//{(1-ratio)*100:.0f} Split')\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 6. Summary Table with Recommendations\n",
    "    print(\"\\n===== Train-Test Split Ratio Experiment Summary =====\")\n",
    "    print(f\"Best Ratio: {best_ratio*100:.0f}/{(1-best_ratio)*100:.0f} Split\")\n",
    "    \n",
    "    # Display metrics for the best ratio\n",
    "    best_perf = experiment_results['best_result']['performance']\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics for {best_ratio*100:.0f}/{(1-best_ratio)*100:.0f} Split:\")\n",
    "    print(f\"- Sharpe Ratio: {best_perf['sharpe_ratio']:.4f}\")\n",
    "    print(f\"- Maximum Drawdown: {best_perf['max_drawdown']:.4f}\")\n",
    "    print(f\"- Trade Frequency: {best_perf['trade_frequency']:.4f}\")\n",
    "    print(f\"- Final Return: {best_perf['final_return']*100:.2f}%\")\n",
    "    print(f\"- Buy & Hold Return: {best_perf['buy_hold_return']*100:.2f}%\")\n",
    "    print(f\"- Outperformance: {best_perf['outperformance']*100:.2f}%\")\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(f\"1. Use the {best_ratio*100:.0f}/{(1-best_ratio)*100:.0f} split ratio for optimal model performance\")\n",
    "    \n",
    "    # Specific recommendations based on the results\n",
    "    if best_ratio == 0.7:\n",
    "        print(\"2. This ratio provides more test data, which is beneficial for robust evaluation\")\n",
    "        print(\"3. Consider ensemble methods to improve performance with this lower training data ratio\")\n",
    "    elif best_ratio == 0.8:\n",
    "        print(\"2. This ratio provides a balanced approach between training and testing data\")\n",
    "        print(\"3. For optimal results, use a periodic model retraining schedule to adapt to new market conditions\")\n",
    "    elif best_ratio == 0.9:\n",
    "        print(\"2. This ratio maximizes training data, capturing more market patterns\")\n",
    "        print(\"3. Consider cross-validation techniques to ensure model generalizability with limited test data\")\n",
    "    \n",
    "    # General recommendation\n",
    "    print(\"4. Implement a sliding window approach in production to continuously retrain the model\")\n",
    "    \n",
    "    return best_ratio\n",
    "\n",
    "# Call the visualization function after running the experiment\n",
    "if 'experiment_results' in locals() and experiment_results:\n",
    "    best_ratio = visualize_ratio_comparison(experiment_results)\n",
    "    print(f\"\\nThe optimal train-test split ratio is: {best_ratio}\")\n",
    " \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
